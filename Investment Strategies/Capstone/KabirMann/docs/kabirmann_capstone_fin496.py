# -*- coding: utf-8 -*-
"""KabirMann_capstone_fin496.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iQuvzFomacJ616Y4evwh4SNyoaQaEjW4

### Libraries
"""

import requests
from newsapi import NewsApiClient
import datetime
import pandas as pd
import numpy as np
import time
import yfinance as yf
import warnings
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.interpolate import make_interp_spline
from pandas.io.formats.style import Styler
import graphviz
from IPython.display import Image, display

warnings.filterwarnings('ignore')

"""### Pulling News

I tried to reach out to DOW for the WSJ one. That actually gave the text of each article. NewsAPI was $449 per month to go back 5 years. The free version only let me go back one month and only allowed 250 requests, which was too little. RavenPack is what UFlorida used to validate that the articles they scraped were actually useful finance articles. I reached out to their support, and their post-discount pricing was 20k to 36k per annum.
"""

# Initialize NewsAPI client
newsapi = NewsApiClient(api_key='83f8f13e0e5a47378fb12f979d10dfde')

def fetch_apple_headlines():
    start_date = datetime.datetime(2024, 4, 15)  # 1 month back
    end_date = datetime.datetime.now()

    current_date = start_date
    headlines = []

    while current_date <= end_date:
        # Format the date to the required format YYYY-MM-DD
        date_str = current_date.strftime('%Y-%m-%d')

        # Fetch the top news headline for Apple stock on the current date
        try:
            all_articles = newsapi.get_everything(q='Apple',
                                                  from_param=date_str,
                                                  to=date_str,
                                                  language='en',
                                                  sort_by='relevancy',
                                                  page_size=1)
            if all_articles['articles']:
                article = all_articles['articles'][0]
                headline = article['title']
                headlines.append({'date': date_str, 'headline': headline})
                print(f"{date_str}: {headline}")

        except Exception as e:
            print(f"Failed to fetch news for {date_str}: {e}")

        # Move to the next day
        current_date += datetime.timedelta(days=1)

    return headlines

# def fetch_apple_headlines(df):
#     # Add a headlines column if it doesn't exist
#     if 'headline' not in df.columns:
#         df['headline'] = None

#     # Ensure the dates column is in datetime format
#     df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0])

#     current_index = 0  # To track the current row in DataFrame

#     while current_index < len(df) and pd.isna(df.iloc[current_index, 1]):
#         # Request API key from user
#         api_key = input("Please enter your NewsAPI key: ")
#         newsapi = NewsApiClient(api_key=api_key)

#         # Process each date in the DataFrame
#         while current_index < len(df) and pd.isna(df.iloc[current_index, 1]):
#             current_date = df.iloc[current_index, 0]
#             date_str = current_date.strftime('%Y-%m-%d')

#             try:
#                 all_articles = newsapi.get_everything(q='Apple',
#                                                       from_param=date_str,
#                                                       to=date_str,
#                                                       language='en',
#                                                       sort_by='relevancy',
#                                                       page_size=1)
#                 if all_articles['articles']:
#                     article = all_articles['articles'][0]
#                     headline = article['title']
#                     df.at[current_index, 'headline'] = headline
#                     print(f"{date_str}: {headline}")
#                 else:
#                     df.at[current_index, 'headline'] = "No headline found"
#                     print(f"{date_str}: No headline found")

#             except Exception as e:
#                 if "apiKeyInvalid" in str(e) or "rateLimited" in str(e):
#                     print(f"API key error or rate limit reached on {date_str}: {e}")
#                     break  # Break the inner loop to request a new API key
#                 else:
#                     print(f"Failed to fetch news for {date_str}: {e}")
#                     df.at[current_index, 'headlines'] = "Error fetching headline"

#             current_index += 1  # Move to the next date

#     return df

"""Prompt (I did not have it return a csv as gemini can't do that):

Pretend you are a financial expert. You are a financial expert with stock recommendation experience. I have uploaded data with dates and headlines for apple. I want you to return two additional data for each date. It should be about the sentiment of the headline. Answer “YES” if good news, “NO” if bad news, or “UNKNOWN” if you are uncertain. Additionally, elaborate with one short and concise sentence.

### Main Functions
"""

def calculate_percentage_change(df, column_name, new_name = 'price_change'):
    """
    This function takes a DataFrame and a column name, calculates the percentage change
    for each row in that column, and replaces the old column with the new percentage change values.

    Parameters:
    df (pd.DataFrame): The input DataFrame.
    column_name (str): The column name for which to calculate the percentage change.

    Returns:
    pd.DataFrame: The DataFrame with the percentage change column.
    """
    # Check if the column exists in the DataFrame
    if column_name not in df.columns:
        raise ValueError(f"Column '{column_name}' not found in DataFrame")

    # Calculate the percentage change
    df[column_name] = df[column_name].pct_change() * 100

    # Replace NaN values that result from pct_change() with 0 or another value if necessary
    df[column_name].fillna(0, inplace=True)

    df.rename(columns={column_name: new_name}, inplace=True)

    return df


def get_average_money_market_rate(date):
    """
    This function pulls the average money market rate from Yahoo Finance for a given date.

    Parameters:
    date (str): The date for which to pull the money market rate in 'YYYY-MM-DD' format.

    Returns:
    float: The average money market rate for the given date.
    """
    # Convert the date string to a pandas Timestamp
    date = pd.to_datetime(date)

    #('^IRX' for 13 Week Treasury Bill)
    ticker_symbol = '^IRX'

    # Fetch historical market data
    ticker = yf.Ticker(ticker_symbol)
    hist = ticker.history(start=date, end=date + pd.Timedelta(days=1))

    # Check if there is data for the given date
    if hist.empty:
        return None  # Return None if no data is available for the given date

    # Extract the average money market rate for the given date
    annual_rate = hist['Close'].iloc[0]

    # Convert the annual rate to a daily rate (assuming daily compounding)
    daily_rate = (1 + annual_rate / 100) ** (1 / 365) - 1

    # Convert daily_rate back to percentage form
    daily_rate_percent = daily_rate * 100

    return daily_rate_percent

def add_money_market_rate_column(df, date_column_name='Date', new_column_name='money_market_rate'):
    """
    This function adds a new column to the DataFrame with the money market rate for each date.

    Parameters:
    df (pd.DataFrame): The input DataFrame.
    date_column_name (str): The name of the column containing the dates. Default is 'Date'.
    new_column_name (str): The name of the new column to add with the money market rate. Default is 'MoneyMarketRate'.

    Returns:
    pd.DataFrame: The DataFrame with the new money market rate column.
    """
    # Ensure the date column is in datetime format
    df[date_column_name] = pd.to_datetime(df[date_column_name])

    # Initialize the new column with NaN values
    df[new_column_name] = float('nan')

    # Loop through each row and get the money market rate for the date
    for index, row in df.iterrows():
        date = row[date_column_name]
        rate = get_average_money_market_rate(date)
        df.at[index, new_column_name] = rate

    return df

def calculate_portfolio_value(df, port_val):
    """
    This function calculates the daily portfolio value based on the sentiment, price changes, and money market rates.

    Parameters:
    df (pd.DataFrame): The input DataFrame containing 'date', 'sentiment', 'price_change', and 'money_market_rate' columns.
    port_val (float): The initial portfolio value.

    Returns:
    pd.DataFrame: A DataFrame with the daily portfolio values.
    """
    # Ensure 'date' column is in datetime format
    df['Date'] = pd.to_datetime(df['Date'])

    # Create a new DataFrame to store the portfolio values
    portfolio_values = []

    # Loop through each row in the DataFrame
    for i in range(len(df) - 1):
        # Get the next day's date
        next_date = df.at[i + 1, 'Date']

        if 'sentiment' in df.columns:
          # Get the sentiment
            sentiment = df.at[i, 'sentiment']

            # Calculate the new portfolio value based on the sentiment
            if sentiment == 'NO':
                # Short the stock
                port_val *= 1 - (df.at[i + 1, 'price_change'] / 100)
            elif sentiment == 'YES':
                # Buy the stock
                port_val *= 1 + (df.at[i + 1, 'price_change'] / 100)
            elif sentiment == 'UNKNOWN':
                # Invest in the money market
                port_val *= 1 + (df.at[i + 1, 'money_market_rate'] / 100)

        else:

          port_val *= 1 + (df.at[i + 1, 'price_change'] / 100)

        # Append the date and portfolio value to the list
        portfolio_values.append({'Date': next_date, 'portfolio_value': port_val})

    # Create a DataFrame from the list
    portfolio_df = pd.DataFrame(portfolio_values)

    return portfolio_df


def add_prices(df, ticker, date_column_name='Date', new_column_name='closing_price', price_type='Close'):
    """
    This function adds a new column to the DataFrame with the S&P 500 prices for each date.

    Parameters:
    df (pd.DataFrame): The input DataFrame containing a date column.
    ticker (str): The ticker symbol for the S&P 500. Default is '^GSPC'.
    date_column_name (str): The name of the column containing the dates. Default is 'Date'.
    new_column_name (str): The name of the new column to add with the S&P 500 prices. Default is 'spx_price'.
    price_type (str): The type of price to add ('Open' or 'Close'). Default is 'Close'.

    Returns:
    pd.DataFrame: The DataFrame with the new S&P 500 price column.
    """
    # Ensure the date column is in datetime format
    df[date_column_name] = pd.to_datetime(df[date_column_name])

    # Validate price_type parameter
    if price_type not in ['Open', 'Close']:
        raise ValueError("price_type must be either 'Open' or 'Close'")

    # Define the ticker symbol for S&P 500
    ticker_symbol = ticker

    # Create a Ticker object
    ticker = yf.Ticker(ticker_symbol)

    # Fetch historical market data
    start_date = df[date_column_name].min()
    end_date = df[date_column_name].max() + pd.Timedelta(days=1)
    hist = ticker.history(start=start_date, end=end_date)

    # Ensure the prices are aligned by date
    hist = hist[[price_type]].reset_index()
    hist['Date'] = hist['Date'].dt.date

    # Merge the historical prices with the original DataFrame
    df[new_column_name] = df[date_column_name].dt.date.map(hist.set_index('Date')[price_type])

    return df

def calc_volatility(stockDF, column_name):
    """
    Calculate the annualized volatility of a given portfolio from a DataFrame.

    Parameters:
    - stockDF: DataFrame containing the portfolio returns.
    - column_name: string, the name of the column for which to calculate the volatility.

    Returns:
    - float, the annualized volatility of the portfolio.
    """
    # Ensure the 'Date' column is in datetime format
    if 'Date' in stockDF.columns:
      stockDF['Date'] = pd.to_datetime(stockDF['Date'])

    stockDF = stockDF.reset_index(drop=True)

    # Calculate daily returns
    stockDF['Daily Return'] = stockDF[column_name].pct_change() + 1

    # Drop the NaN values that result from the pct_change calculation
    stockDF = stockDF.dropna(subset=['Daily Return'])

    # Calculate the daily volatility (standard deviation)
    daily_volatility = stockDF['Daily Return'].std(ddof=0)

    # Annualize the daily volatility
    annualized_volatility = np.sqrt(252) * daily_volatility

    stockDF.drop(columns='Daily Return', inplace=True)

    return annualized_volatility

def calc_sharpe(df, column, daily_risk_free_rate=0.0):
    """
    Calculates the Sharpe Ratio for a given column of price data in a DataFrame.

    Parameters:
    - df (pd.DataFrame): DataFrame containing the price data.
    - column (str): The column name containing price data.
    - risk_free_rate (float): Annual risk-free rate expressed as a percentage.

    Returns:
    - float: The Sharpe Ratio.
    """
    # Convert prices to daily returns
    df['Returns'] = df[column].pct_change() * 100  # convert to percentage

    # Drop any NaN values that arise from pct_change()
    df = df.dropna()

    # Calculate mean return and standard deviation of the returns
    mean_return = df['Returns'].mean()
    std_dev = df['Returns'].std()

    # Check the timeframe of the data
    num_days = (df.index[-1] - df.index[0]).days

    # Annualize mean return if timeframe is less than one year
    if num_days < 365:
        mean_return = mean_return * (365 / num_days)

    # Calculate Sharpe Ratio
    sharpe_ratio = (mean_return - daily_risk_free_rate) / std_dev

    return sharpe_ratio


def calc_beta(df, portfolio_col, benchmark_col):
    """
    Calculates the beta of a portfolio relative to a benchmark.

    Parameters:
    - df (pd.DataFrame): DataFrame containing the price data.
    - portfolio_col (str): Column name for the portfolio price data.
    - benchmark_col (str): Column name for the benchmark price data.

    Returns:
    - float: Beta of the portfolio.
    """
    # Convert prices to daily returns
    df['Portfolio Returns'] = df[portfolio_col].pct_change()
    df['Benchmark Returns'] = df[benchmark_col].pct_change()

    # Drop any NaN values that arise from pct_change()
    df = df.dropna()

    # Calculate covariance between the portfolio returns and the benchmark returns
    covariance_matrix = np.cov(df['Portfolio Returns'], df['Benchmark Returns'])
    covariance = covariance_matrix[0, 1]

    # Calculate variance of the benchmark returns using sample variance (ddof=1)
    variance = np.var(df['Benchmark Returns'], ddof=1)

    # Calculate beta
    beta = covariance / variance

    return beta

def calc_annual_return(stockDF, column_name):
    """
    Calculate the annual return of a given portfolio from a DataFrame.

    Parameters:
    - stockDF: DataFrame containing the portfolio values.
    - column_name: string, the name of the column for which to calculate the annual return.

    Returns:
    - float, the annual return of the portfolio.
    """
    # Ensure the 'Date' index is in datetime format
    stockDF.index = pd.to_datetime(stockDF.index)

    # Calculate the total return
    total_return = stockDF[column_name].iloc[-1] / stockDF[column_name].iloc[0] - 1

    # Calculate the number of periods in years
    num_years = (stockDF.index[-1] - stockDF.index[0]).days / 365.25

    # Convert the total return to annual return
    annual_return = (1 + total_return) ** (1 / num_years) - 1

    return annual_return

def calc_total_return(stockDF, column_name):
    """
    Calculate the total return of a given portfolio from a DataFrame.

    Parameters:
    - stockDF: DataFrame containing the portfolio values.
    - column_name: string, the name of the column for which to calculate the total return.

    Returns:
    - float, the total return of the portfolio.
    """
    # Calculate the total return
    total_return = stockDF[column_name].iloc[-1] / stockDF[column_name].iloc[0] - 1

    return total_return

def get_metrics(df, benchmark_column):

  metrics = pd.DataFrame(columns=df.columns)

  #volatility
  volatility = {}

  for column in df.columns:
      volatility[column] = calc_volatility(df.copy(), column)
  metrics.loc['Volatility'] = volatility

  #sharpe ratio
  sharpe_ratio = {}

  for column in df.columns:
      sharpe_ratio[column] = calc_sharpe(df.copy(), column)
  metrics.loc['Sharpe Ratio'] = sharpe_ratio

  #beta
  beta = {}

  for column in df.columns:
      beta[column] = calc_beta(df.copy(), column, benchmark_column)
  metrics.loc['Beta'] = beta

  #annual return
  annual_return = {}

  for column in df.columns:
      annual_return[column] = calc_annual_return(df.copy(), column)
  metrics.loc['Annual Return'] = annual_return

  #total return
  total_return = {}

  for column in df.columns:
      total_return[column] = calc_total_return(df.copy(), column)
  metrics.loc['Total Return'] = total_return

  if 'Daily Return' in metrics:
    metrics.drop(columns='Daily Return', inplace=True)

  metrics.loc['Annual Return'] = metrics.loc['Annual Return'].apply(lambda x: f"{x:.1%}")
  metrics.loc['Total Return'] = metrics.loc['Total Return'].apply(lambda x: f"{x:.1%}")

  metrics.loc['Beta'] = metrics.loc['Beta'].apply(lambda x: f"{x:.2f}")
  metrics.loc['Sharpe Ratio'] = metrics.loc['Sharpe Ratio'].apply(lambda x: f"{x:.2f}")
  metrics.loc['Volatility'] = metrics.loc['Volatility'].apply(lambda x: f"{x:.2f}")

  def color_negative_red(val):
             #red                              #green
    color = '#cc0100' if '-' in str(val) else '#6aa84f'
    return f'color: {color}'

  # Applying the color function to the relevant rows
  metrics = metrics.style.applymap(color_negative_red, subset=pd.IndexSlice[['Annual Return', 'Total Return'], :])

  return metrics

"""### Cleaning"""

#Upload CSV with prices and headline rankings from ChatGPT and Gemini

gpt4o = pd.read_csv("/content/gpt_4o.csv")
gpt35 = pd.read_csv("/content/gpt_35.csv")
gemini_advanced = pd.read_csv("/content/gemini_advanced.csv")
gemini_basic = pd.read_csv("/content/gemini_basic.csv")

#add Apple opening prices

gpt4o = add_prices(gpt4o, ticker='AAPL')
gpt35 = add_prices(gpt35, ticker='AAPL')
gemini_advanced = add_prices(gemini_advanced, ticker='AAPL')
gemini_basic = add_prices(gemini_basic, ticker='AAPL')

gpt4o = calculate_percentage_change(gpt4o, "closing_price")
gpt35 = calculate_percentage_change(gpt35, "closing_price")
gemini_advanced = calculate_percentage_change(gemini_advanced, "closing_price")
gemini_basic = calculate_percentage_change(gemini_basic, "closing_price")

gpt4o = add_money_market_rate_column(gpt4o)
gpt35 = add_money_market_rate_column(gpt35)
gemini_advanced = add_money_market_rate_column(gemini_advanced)
gemini_basic = add_money_market_rate_column(gemini_basic)

display(gemini_advanced)

"""### Returns"""

# SPX

spx = gpt4o.iloc[:, [0]]
spx_prices = add_prices(spx, ticker='^GSPC', new_column_name='spx_price')
spx_per_change = calculate_percentage_change(spx_prices, 'spx_price')

spx_per_change

gpt4o_value = calculate_portfolio_value(gpt4o, 100)
gpt35_value = calculate_portfolio_value(gpt35, 100)
gemini_advanced_value = calculate_portfolio_value(gemini_advanced, 100)
gemini_basic_value = calculate_portfolio_value(gemini_basic, 100)
spx_value = calculate_portfolio_value(spx_per_change, 100)

gpt4_value = gpt4o_value.rename(columns={'portfolio_value': 'ChatGPT 4o'})
gpt35_value = gpt35_value.rename(columns={'portfolio_value': 'ChatGPT 3.5'})
gemini_advanced_value = gemini_advanced_value.rename(columns={'portfolio_value': 'Gemini Advanced'})
gemini_basic_value = gemini_basic_value.rename(columns={'portfolio_value': 'Gemini Free'})
spx_value = spx_value.rename(columns={'portfolio_value': 'S&P 500'})

total_returns = pd.concat([gpt4_value.set_index('Date'), gpt35_value.set_index('Date'),
                           gemini_advanced_value.set_index('Date'), gemini_basic_value.set_index('Date'),
                           spx_value.set_index('Date')], axis=1)

total_returns.reset_index(inplace=True)

total_returns['Date'] = pd.to_datetime(total_returns['Date'])


normalize = pd.DataFrame([[pd.Timestamp('2024-04-15'), 100, 100, 100, 100, 100]],
                        columns=total_returns.columns)


total_returns = pd.concat([normalize, total_returns]).reset_index(drop=True)

total_returns.set_index('Date', inplace=True)

total_returns

"""### Graphs and Metrics"""

#RETURNS COMPARISON PLOT

#Uncomment the below line if the date index is not set
# total_returns.set_index('Date', inplace=True)

# #brown, green, black
# custom_colors = {
#     'Chat GPT 4o': '#6c584c',
#     'ChatGPT 3.5': '#dde5b6',
#     'Gemini Advanced': '#432818',
#     'Gemini Free': '#a98467',
#     'S&P 500': '#adc178'
# }

#teal, yellow, orange, grey, black
custom_colors = {
    'ChatGPT 4o': '#000000',
    'ChatGPT 3.5': '#019ca6',
    'Gemini Advanced': '#DC582A',
    'Gemini Free': '#f1b535',
    'S&P 500': '#959595'
}

# Create the line plot
plt.figure(figsize=(14, 8))

# Remove gridlines and set style
sns.set(style="white")

# Plot all columns with specified colors and thicker lines
for column in total_returns.columns:
    sns.lineplot(data=total_returns[column], label=column, color=custom_colors.get(column), linewidth=2.5)

# Add title and labels
plt.title('Performance Over Time', fontsize=20, fontweight='bold', pad=30)
plt.xlabel('Date', fontsize=16, fontweight='bold', labelpad=20)
plt.ylabel('Portfolio Value', fontsize=16, fontweight='bold', labelpad=20)

# Rotate the x-axis labels for better readability
plt.xticks(rotation=45, fontsize=12)
plt.yticks(fontsize=12)

# Add a legend
plt.legend(title='Portfolio', fontsize=14, title_fontsize='16', loc='upper left', frameon=False)

# Display the plot
plt.tight_layout()
plt.show()

metrics = get_metrics(total_returns, 'S&P 500')

metrics

workflow = graphviz.Digraph("workflow", comment="Sentiment Analysis Investment Strategy Workflow")

# Set graph attributes for better visualization

workflow.attr(rankdir='LR', size='10000,5000')  # Increased size for better fitting

# Data Collection
workflow.node("A", "Data Collection", shape="box")
workflow.node("A1", "Yahoo Finance", shape="ellipse")
workflow.node("A2", "Bloomberg", shape="ellipse")
workflow.node("A3", "NewsAPI", shape="ellipse")
workflow.edge("A1", "B")
workflow.edge("A2", "B")
workflow.edge("A3", "B")

# Data Conversion
workflow.node("B", "Data Conversion", shape="box")
workflow.edge("B", "C", label="Convert to Daily Percentage Change")

# Sentiment Analysis Using LLMs
workflow.node("C", "Sentiment Analysis Using LLMs", shape="box")
workflow.edge("C", "D", label="Manually Use LLMs")
workflow.edge("C", "D1", label="Modify Prompt as Needed")

# Portfolio Simulation
workflow.node("D", "Simulate Portfolio", shape="box")

# Performance Comparison
workflow.node("E", "Compare Portfolio Metrics", shape="box")
workflow.edge("D", "E")

# Additional Nodes
workflow.node("D1", "Modify Prompt", shape="ellipse")
workflow.edge("D1", "D")  # Add arrow from "Modify Prompt" to "Simulate Portfolio"

# Add subgraphs for clarity
with workflow.subgraph(name="cluster_0") as c:
    c.attr(label="Data Sources", style="dashed")
    c.node("A1")
    c.node("A2")
    c.node("A3")

with workflow.subgraph(name="cluster_1") as c:
    c.attr(label="Data Processing", style="dashed")
    c.node("B")

with workflow.subgraph(name="cluster_2") as c:
    c.attr(label="Analysis", style="dashed")
    c.node("C")
    c.node("D")
    c.node("D1")
    c.node("E")

# Render and save the graph as a PNG file
workflow.render("/content/flowchart", format="png")

# Display the graph image
Image(filename="/content/flowchart.png")

